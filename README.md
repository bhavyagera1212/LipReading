🚀**Overview**

This project is all about teaching AI to read lips! 🧠💡 Using deep learning, we built a model that analyzes 30 frames per word to recognize spoken words from lip movements. The model achieved moderate accuracy in real-time testing, and we’re working on making it even better!


📊 **Dataset**

🏷️ Words are represented by 30-frame sequences.

🎥 Frames were captured manually.


🏗️ **Model Architecture**

🖼️ Feature Extraction: Convolutional Neural Networks (CNNs) extract visual patterns.

🎯 Final Classification: Fully connected layers with softmax activation.

🚀 Optimization: Adam optimizer + categorical cross-entropy loss.


📈 **Results**

✅ The model achieved moderate accuracy on real-time test data.


🔥 **Future Improvements**

📌 Expand dataset size and improve quality for better generalization.

⚡ Experiment with Transformer-based models for improved accuracy.

🛠️ Fine-tune preprocessing techniques to enhance feature extraction.

🎯 Optimize hyperparameters to boost performance.

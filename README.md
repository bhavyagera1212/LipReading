ğŸš€**Overview**

This project is all about teaching AI to read lips! ğŸ§ ğŸ’¡ Using deep learning, we built a model that analyzes 30 frames per word to recognize spoken words from lip movements. The model achieved moderate accuracy in real-time testing, and weâ€™re working on making it even better!


ğŸ“Š **Dataset**

ğŸ·ï¸ Words are represented by 30-frame sequences.

ğŸ¥ Frames were captured manually.


ğŸ—ï¸ **Model Architecture**

ğŸ–¼ï¸ Feature Extraction: Convolutional Neural Networks (CNNs) extract visual patterns.

ğŸ¯ Final Classification: Fully connected layers with softmax activation.

ğŸš€ Optimization: Adam optimizer + categorical cross-entropy loss.


ğŸ“ˆ **Results**

âœ… The model achieved moderate accuracy on real-time test data.


ğŸ”¥ **Future Improvements**

ğŸ“Œ Expand dataset size and improve quality for better generalization.

âš¡ Experiment with Transformer-based models for improved accuracy.

ğŸ› ï¸ Fine-tune preprocessing techniques to enhance feature extraction.

ğŸ¯ Optimize hyperparameters to boost performance.
